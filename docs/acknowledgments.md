## Acknowledgments

Thank you to the staff of the [Ohio Supercomputer Center](https://osc.edu), [University at Buffalo Center for Computational Research](https://buffalo.edu/ccr), and [Virginia Tech Advanced Research Computing](https://arc.vt.edu/) for developing this tutorial.  

#### Funding
Thank you to the [National Science Foundation](https://nsf.gov) for the supporting the development of [Open OnDemand](https://openondemand.org) and [Open XDMoD](https://open.xdmod.org/)  
- Open OnDemand NSF award numbers: [NSF#1534949](https://www.nsf.gov/awardsearch/showAward?AWD_ID=1534949) and [NSF#1935725](https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835725)  

- XDMoD NSF award numbers: [ACI 1025159](https://nsf.gov/awardsearch/showAward?AWD_ID=1025159), [ACI 1445806](https://nsf.gov/awardsearch/showAward?AWD_ID=1445806), and [OAC 2137603](https://www.nsf.gov/awardsearch/showAward?AWD_ID=2137603)  

#### Publications
- Andrew E. Bruno, Doris J. Sajdak. 2021. ColdFront: Resource Allocation Management System (PEARC ’21). Association for Computing Machinery, New York, NY, USA. DOI:[10.1145/3437359.3465585](https://doi.org/10.1145/3437359.3465585)  

- Dave Hudak et al., (2018). Open OnDemand: A web-based client portal for HPC centers. Journal of Open Source Software, 3(25), 622, https://doi.org/10.21105/joss.00622  

- Jeffrey T. Palmer, Steven M. Gallo, Thomas R. Furlani, Matthew D. Jones, Robert L. DeLeon, Joseph P. White, Nikolay Simakov, Abani K. Patra, Jeanette Sperhac, Thomas Yearke, Ryan Rathsam, Martins Innus, Cynthia D. Cornelius, James C. Browne, William L. Barth, Richard T. Evans, “Open XDMoD: A Tool for the Comprehensive Management of High-Performance Computing Resources”, Computing in Science & Engineering, Vol 17, Issue 4, 2015, pp. 52-62. [10.1109/MCSE.2015.68](http://dx.doi.org/10.1109/MCSE.2015.68)  

#### Workshops
This tutorial was first presented at the PRACTICE AND EXPERIENCE IN ADVANCED RESEARCH COMPUTING 2020 Virtual Conference (PEARC20) - https://pearc.acm.org/pearc20/  

A condensed version of this tutorial was presented at [Gateways 2020](https://sciencegateways.org/web/gateways2020)  

An updated version of this tutorial was presented at the PRACTICE AND EXPERIENCE IN ADVANCED RESEARCH COMPUTING 2021 Virtual Conference (PEARC21) - https://pearc.acm.org/pearc21/  

An updated version of this tutorial was presented at the PRACTICE AND EXPERIENCE IN ADVANCED RESEARCH COMPUTING 2022 Conference (PEARC22), Boston, MA - https://pearc.acm.org/pearc22/ 

A condensed, half day version of this tutorial will be presented at ISC High Performance Conference 2023, Hamburg, Germany - https://www.isc-hpc.com/  

An updated version of this tutorial will be presented at the PRACTICE AND EXPERIENCE IN ADVANCED RESEARCH COMPUTING 2023 Conference (PEARC23), Portland, OR - https://pearc.acm.org/pearc23/ 

#### Container Development

The multi-container Slurm cluster using docker-compose is loosely based on the following:

- https://github.com/giovtorres/slurm-docker-cluster
- https://github.com/OSC/ood-images/tree/master/docker-with-slurm


[Back to Start](../README.md)
